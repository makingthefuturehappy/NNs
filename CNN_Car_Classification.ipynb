{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Car_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makingthefuturehappy/NNs/blob/main/CNN_Car_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JFDGIFcpuqF"
      },
      "source": [
        "results:<br>\n",
        "v1.0 'Xception': loss: 0.1225 | accuracy: 0.9696 | submission - 0.93018<br>\n",
        "v1.1. 'Xception' with LR optimization & Batch Optimization: loss: 0.1470 |  accuracy: 0.9693 | submission - 0.93962<br>\n",
        "v2.0 'EfficientNetB4' with LR optimization & Batch Optimization loss: 0.3996 | accuracy: 0.9568 | submission - 0.93018<br>\n",
        "v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization + dataset v3 loss: 0.1252 | accuracy: 0.9926 | submission - 0.96044<br>\n",
        "v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization + dataset v3 + ds v4 loss: 0.0704 - accuracy: 0.9881 | submission - 0.96029\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUISL8nAGGMG",
        "cellView": "both"
      },
      "source": [
        "%%capture\n",
        "\n",
        "#@title Libs setup\n",
        "\n",
        "#@title Libs and Drivers setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import zipfile\n",
        "import csv\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import PIL\n",
        "from PIL import ImageOps, ImageFilter\n",
        "#увеличим дефолтный размер графиков\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 5\n",
        "#графики в svg выглядят более четкими\n",
        "%config InlineBackend.figure_format = 'svg' \n",
        "%matplotlib inline\n",
        "%config IPCompleter.greedy=True  # более лучший автокомплит в блокноте\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = 'https://drive.google.com/drive/folders/1Sc9qSYEE4Mf2z1MVccxwcUCW3MqTdnwa'\n",
        "\n",
        "!pip install gTTS #text to Speach lib for notifications\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "def Notification(text = 'task is done'):\n",
        "  tts = gTTS(text)\n",
        "  print(text)\n",
        "  tts.save('notification.wav')\n",
        "  sound_file = 'notification.wav'\n",
        "  return Audio(sound_file, autoplay=True)\n",
        "\n",
        "# from google.colab import output\n",
        "# def Notification():\n",
        "#   output.eval_js('new Audio(\"https://soundslibmp3.ru/sounds/1599371653_intro-35.mp3\").play()')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJUPMjkiG3lh",
        "cellView": "both",
        "outputId": "aafdabd0-ae5f-4a5b-c45d-49196cc4f7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "#@title system check\n",
        "print('Python       :', sys.version.split('\\n')[0])\n",
        "print('Numpy        :', np.__version__)\n",
        "print('Tensorflow   :', tf.__version__)\n",
        "print('Keras        :', tf.keras.__version__)\n",
        "tf.test.gpu_device_name() ## Проверяем что у нас работает GPU\n",
        "!nvidia-smi -L ##GPU count and name\n",
        "Notification('hardware and libs setup is done')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python       : 3.6.9 (default, Jul 17 2020, 12:50:27) \n",
            "Numpy        : 1.18.5\n",
            "Tensorflow   : 2.3.0\n",
            "Keras        : 2.4.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-f4970bd1-6fc3-61cc-ee95-00b63ae469b3)\n",
            "hardware and libs setup is done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mwiYkC3JyDX",
        "cellView": "both"
      },
      "source": [
        "#@title Variables Setup\n",
        "EPOCHS               = 7  # эпох на обучение\n",
        "BATCH_SIZE           = 256 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\n",
        "LR                   = 1e-4\n",
        "VAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n",
        "\n",
        "CLASS_NUM            = 10  # количество классов в нашей задаче\n",
        "IMG_SIZE             = 224 # какого размера подаем изображения в сеть\n",
        "IMG_CHANNELS         = 3   # у RGB 3 канала\n",
        "input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
        "\n",
        "PATH = '/content/'\n",
        "PATH_GDRIVE = '/content/drive/My Drive/Colab Notebooks/car classification/data/'\n",
        "train_dataset_name = 'train_ds_v5.zip'\n",
        "\n",
        "# Устаналиваем конкретное значение random seed для воспроизводимости\n",
        "# os.makedirs(PATH,exist_ok=False)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)  \n",
        "PYTHONHASHSEED = 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAxRffMIVEp8",
        "cellView": "both",
        "outputId": "7732eaf9-b1f4-437e-8946-129e15ff2e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "# @title Dataset Setup\n",
        "print('unpacking the pics...')\n",
        "\n",
        "# train DataSet Setup\n",
        "print('unpacking train dataset...')\n",
        "with zipfile.ZipFile(PATH_GDRIVE + 'train/' + train_dataset_name,\"r\") as z:\n",
        "  z.extractall(PATH + 'train')\n",
        "\n",
        "## test DataSet Setup\n",
        "print('unpacking test dataset...')\n",
        "with zipfile.ZipFile(PATH_GDRIVE + 'test/test_upload.zip',\"r\") as z:\n",
        "        z.extractall(PATH)\n",
        "\n",
        "## copy files from G-Drive to Colab env.\n",
        "%cp -av '/content/drive/My Drive/Colab Notebooks/car classification/data/train.csv' '/content'\n",
        "%cp -av '/content/drive/My Drive/Colab Notebooks/car classification/data/sample-submission.csv' '/content'\n",
        "\n",
        "print('cleaning folders...')\n",
        "shutil.rmtree(PATH + 'train/__MACOSX')\n",
        "shutil.rmtree(PATH + '__MACOSX')\n",
        "# shutil.rmtree(PATH + 'sample_data')\n",
        "print('data uploaded...')\n",
        "Notification('pictures uploaded')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unpacking the pics...\n",
            "unpacking train dataset...\n",
            "unpacking test dataset...\n",
            "'/content/drive/My Drive/Colab Notebooks/car classification/data/train.csv' -> '/content/train.csv'\n",
            "'/content/drive/My Drive/Colab Notebooks/car classification/data/sample-submission.csv' -> '/content/sample-submission.csv'\n",
            "cleaning folders...\n",
            "data uploaded...\n",
            "pictures uploaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXVw8GCFXTGG",
        "cellView": "form"
      },
      "source": [
        "# @title Delete all internal directories (muted)\n",
        "# import shutil\n",
        "\n",
        "# for dir_name in range (0,9,1):\n",
        "#   dir_name = str(dir_name)\n",
        "#   try:\n",
        "#     shutil.rmtree('/content/' + str(dir_name))\n",
        "#   except: print(dir_name, 'dir does not exist')\n",
        "\n",
        "# try:\n",
        "#   shutil.rmtree('/content/' + str('__MACOSX'))\n",
        "# except: print(dir_name, 'dir does not exist')\n",
        "\n",
        "# try:\n",
        "#   shutil.rmtree(PATH + 'train/')\n",
        "#   shutil.rmtree(PATH + 'test_upload/')\n",
        "# except: print('deleting all files error')\n",
        "\n",
        "# print('allDone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82lojgMBZxap",
        "cellView": "form"
      },
      "source": [
        "#@title Random pics examples (muted)\n",
        "# print('random pics examples')\n",
        "\n",
        "# train_df = pd.read_csv(PATH+\"train.csv\")\n",
        "# sample_submission = pd.read_csv(PATH+\"sample-submission.csv\")\n",
        "# print('dataset examples\\n',\n",
        "#       train_df.head(),\n",
        "#       '\\n\\ncategories destribution\\n',\n",
        "#       train_df.Category.value_counts())\n",
        "\n",
        "# plt.figure(figsize=(12,8))\n",
        "\n",
        "# random_image = train_df.sample(n=9)\n",
        "# random_image_paths = random_image['Id'].values\n",
        "# random_image_cat = random_image['Category'].values\n",
        "\n",
        "# for index, path in enumerate(random_image_paths):\n",
        "#     im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n",
        "#     plt.subplot(3,3, index+1)\n",
        "#     plt.imshow(im)\n",
        "#     plt.title('Class: '+str(random_image_cat[index]))\n",
        "#     plt.axis('off')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLVi-F5IWjKQ",
        "cellView": "form",
        "outputId": "ef1ca139-be57-45dc-e33a-af3cfdb71055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#@title Pics Generator setup\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    validation_split=VAL_SPLIT, # set validation split\n",
        "    ##pics augumentation\n",
        "    # horizontal_flip=False\n",
        "    # rotation_range = 5,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1\n",
        "    )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    PATH + 'train/',      # директория где расположены папки с картинками \n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True, seed=RANDOM_SEED,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    PATH + 'train/',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True, seed=RANDOM_SEED,\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "sample_submission = pd.read_csv(PATH+\"sample-submission.csv\")\n",
        "test_sub_generator = test_datagen.flow_from_dataframe( \n",
        "    dataframe=sample_submission,\n",
        "    directory=PATH+'test_upload/',\n",
        "    x_col=\"Id\",\n",
        "    y_col=None,\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    seed=RANDOM_SEED,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13232 images belonging to 10 classes.\n",
            "Found 2329 images belonging to 10 classes.\n",
            "Found 6675 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io8kBhFM-EUa",
        "cellView": "form"
      },
      "source": [
        "#@title plot_result function\n",
        "def plot_result(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()  \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOWqJtnHiMeQ"
      },
      "source": [
        "## basic experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kjb9wwgh83v"
      },
      "source": [
        "### Xception tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_LBnB9qYeKL",
        "cellView": "both"
      },
      "source": [
        "#@title NN_v1.0 Xception (setup)\n",
        "model_name = 'v1_0.hdf5'\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n",
        "# New head setup\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "# and a logistic layer -- let's say we have 10 classes\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=optimizers.Adam(lr=LR), \n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKK_-IDhY5ES",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v1.0 Xception (training)\n",
        "checkpoint = ModelCheckpoint(model_name ,\n",
        "                             monitor = ['val_accuracy'],\n",
        "                             verbose = 1, \n",
        "                             mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks=[tensorboard_callback]\n",
        "        )\n",
        "\n",
        "model.save(PATH_GDRIVE + \"models/\" + model_name)\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1PZbgI_Z83X",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v1.1 Xception with LR optimization & Batch Optimization (setup)\n",
        "%reload_ext tensorboard\n",
        "model_name = 'v1_1.hdf5'\n",
        "!rm -rf ./logs/\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                                      histogram_freq=1)\n",
        "\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, \n",
        "                                                                                            decay_steps = 100, \n",
        "                                                                                            decay_rate = 0.9)),\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1, # new_lr = lr * factor. \n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    min_delta=0.0001, cooldown=1, min_lr=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Z2hTLX-1hu",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v1.1 Xception with LR optimization & Batch Optimization (training)\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY0xn1gRFzuh"
      },
      "source": [
        "### EfficientNetB4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlVBIHfwF6mU"
      },
      "source": [
        "### ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUwkoWL5GFnv",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization (setup)\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "model_name = 'v3_0_ds4.hdf5'\n",
        "base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                          include_top=False,\n",
        "                          weights=\"imagenet\")\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, \n",
        "                                                                                            decay_steps = 100, \n",
        "                                                                                            decay_rate = 0.9)),\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1, # new_lr = lr * factor. \n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    min_delta=0.0001, cooldown=1, min_lr=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt6qEGq1HI6g",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization (training)\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "plot_result(history)\n",
        "Notification()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTNw2u_cGsTN"
      },
      "source": [
        "### without ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qSNZb8GMG4Pw"
      },
      "source": [
        "#@title NN_v3.1 'InceptionResNetV2' with No LR optimization & Batch Optimization (setup)\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "model_name = 'v3_1_ds2.hdf5'\n",
        "base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                          include_top=False,\n",
        "                          weights=\"imagenet\")\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, \n",
        "                                                                                            decay_steps = 100, \n",
        "                                                                                            decay_rate = 0.9)),\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "AUShqOqFG50E"
      },
      "source": [
        "#@title NN_v3.1 'InceptionResNetV2' with No LR optimization & Batch Optimization (training)\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "plot_result(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpQTRUTV1UWl"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPx2Nf69ZxMi"
      },
      "source": [
        "**the idea is:**<br>\n",
        "- to find the  optimal hyperparamets by using TensorBoard (TB)<br>\n",
        "- train the net<br>\n",
        "- add more augmented pics to the categories with the highest confusion according to the confusion matrix<br>\n",
        "- re-train the net<br>\n",
        "- apply the fine-tuning<br><br>\n",
        "<b>TO DO:</b><br>\n",
        "<input type=\"checkbox\">prepare the middle-sized augmented dataset (train_ds_v5))<br>\n",
        "<input type=\"checkbox\">setup TB, API HParams<br>\n",
        "<input type=\"checkbox\">pre-train CNN (1 EPOCH) to find the optimal param <br>\n",
        "<input type=\"checkbox\">full train CNN with the optimal param <br>\n",
        "<input type=\"checkbox\">ConfMatrix setup<br>\n",
        "<input type=\"checkbox\">add more augmented pics (train_ds_v6)<br> \n",
        "<input type=\"checkbox\">full train<br>\n",
        "<input type=\"checkbox\">fine tuning<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtz7mg41E_hE",
        "outputId": "db87780e-78c0-40e9-a50c-acd82fb9d632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#@title Tensorboard Setup\n",
        "%load_ext tensorboard\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "metrics_callback = tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by6tXoYAx4o7",
        "outputId": "d37985e2-ecd7-4594-f049-283328d1c518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#@title Tensorboard HyperParams Setup\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "##list of params to find optimumal set\n",
        "# HP_NUM_UNITS=hp.HParam('num_units', hp.Discrete([ 256, 512]))\n",
        "# HP_DROPOUT=hp.HParam('dropout', hp.RealInterval(0.1, 0.2, 0.3))\n",
        "HP_LEARNING_RATE= hp.HParam('learning_rate', hp.Discrete([1e-3, 5e-4, 1e-4]))\n",
        "HP_OPTIMIZER=hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n",
        "\n",
        "METRIC_ACCURACY='accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "      hparams=[HP_OPTIMIZER, HP_DROPOUT, HP_LEARNING_RATE],\n",
        "      metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
        "      )\n",
        "\n",
        "hp_callback = hp.KerasCallback(logdir, hparams)  # log hparams"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-c3ba20515ad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/hparam_tuning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   hp.hparams_config(\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHP_OPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHP_DROPOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHP_LEARNING_RATE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC_ACCURACY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'HP_DROPOUT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trzXx-HXDD_W",
        "cellView": "both"
      },
      "source": [
        "#@title Confusion Matrix Log Setup\n",
        "#source: https://www.tensorflow.org/tensorboard/image_summaries\n",
        "\n",
        "def plot_confusion_matrix(cm, # (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "                          class_names # (array, shape = [n]): String names of the integer classes):\n",
        "\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Compute the labels from the normalized confusion matrix.\n",
        "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure\n",
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(test_images)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "  # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# !rm -rf logs/image\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_kePxVftUQe",
        "cellView": "form"
      },
      "source": [
        "#@title CNN model setup\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "def model_setup(train_setup = False, # Freez the NN body to train only head\n",
        "                model_name = 'InceptionResNetV2'):\n",
        "  model_name = model_name\n",
        "  base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                                 include_top=False,\n",
        "                                 weights=\"imagenet\"\n",
        "                                 )\n",
        "  # Freeze the base_model\n",
        "  base_model.trainable = train_setup\n",
        "\n",
        "  x = base_model.output\n",
        "  x = BatchNormalization()(x, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOg1ZNIv6FLm",
        "cellView": "both"
      },
      "source": [
        "#@title CNN optimal param research\n",
        "!rm -rf ./logs/ #clean existing logs\n",
        "\n",
        "model = model_setup(train_setup = False,\n",
        "                    model_name = 'InceptionResNetV2')\n",
        "\n",
        "model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = 1,\n",
        "        callbacks = [cm_callback,\n",
        "                     tensorboard_callback,\n",
        "                     hp_callback\n",
        "                     ]\n",
        "\n",
        "Notification('parameters research is done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6KLjaIuKLlw"
      },
      "source": [
        "%load_ext tensorboard\n",
        "# !rm -rf ./logs/ #clean existing logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "7_N-yTpWw0uS"
      },
      "source": [
        "#@title CNN with optimal params training\n",
        "optimal_LR = LR\n",
        "model_name = 'InceptionResNetV2_optimal.hdf5'\n",
        "model = model_setup(train_setup = False,\n",
        "                    model_name = model_name)\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(LR = optimal_LR, \n",
        "                                                               decay_steps = 100, \n",
        "                                                               decay_rate = 0.9))\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = learning_rate,\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = [tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
        "                     hp.KerasCallback(logdir, hparams)]  # log hparams\n",
        "                    \n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "Notification('Neural Network Training is done')\n",
        "\n",
        "##live tensorboard\n",
        "# !tensorboard dev upload --logdir logs --name \"Alex_test\" --description \"Alex_description\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuFu1qa8xWKS",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v3.2 'InceptionResNetV2' with LR & Batch Optimization + FineTuning (fine-tuning)\n",
        "model_name = 'v3_2_ds4_finetuned.hdf5'\n",
        "base_model.trainable = True\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(1e-5))\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "plot_result(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8cDwP6CoWu"
      },
      "source": [
        "## submission generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lMVvQpj5f2R"
      },
      "source": [
        "model.load_weights(PATH_GDRIVE + 'models/'+\n",
        "                  #  'v1_0.hdf5',\n",
        "                  #  'v1_1.hdf5',\n",
        "                  #  'v2_0.hdf5',\n",
        "                  #  'v3_0.hdf5',\n",
        "                  #  'v3_1.hdf5',\n",
        "                  #  'v3_0_ds3.hdf5',\n",
        "                  #  'v3_0_ds4.hdf5',\n",
        "                   model_name\n",
        "                   )\n",
        "scores = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "test_sub_generator.reset()\n",
        "predictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n",
        "predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
        "label_map = (train_generator.class_indices)\n",
        "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
        "predictions = [label_map[k] for k in predictions]\n",
        "\n",
        "filenames_with_dir=test_sub_generator.filenames\n",
        "submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n",
        "submission['Id'] = submission['Id'].replace('test_upload/','')\n",
        "submission.to_csv(PATH_GDRIVE + 'submission.csv', index=False)\n",
        "print('Submit saved.')\n",
        "Notification()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXRiQ_h3voF"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(),signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}