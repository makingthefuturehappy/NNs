{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Car_Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makingthefuturehappy/NNs/blob/main/CNN_Car_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JFDGIFcpuqF"
      },
      "source": [
        "results:<br>\n",
        "v1.0 'Xception': loss: 0.1225 | accuracy: 0.9696 | submission - 0.93018<br>\n",
        "v1.1. 'Xception' with LR optimization & Batch Optimization: loss: 0.1470 |  accuracy: 0.9693 | submission - 0.93962<br>\n",
        "v2.0 'EfficientNetB4' with LR optimization & Batch Optimization loss: 0.3996 | accuracy: 0.9568 | submission - 0.93018<br>\n",
        "v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization + dataset v3 loss: 0.1252 | accuracy: 0.9926 | submission - 0.96044<br>\n",
        "v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization + dataset v3 + ds v4 loss: 0.0704 - accuracy: 0.9881 | submission - 0.96029\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUISL8nAGGMG",
        "cellView": "form",
        "outputId": "057c6bc1-e984-45a2-8e51-602eedc442a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#@title Libs and Drivers setup\n",
        "\n",
        "%%capture\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import zipfile\n",
        "import csv\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import PIL\n",
        "from PIL import ImageOps, ImageFilter\n",
        "#увеличим дефолтный размер графиков\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 5\n",
        "#графики в svg выглядят более четкими\n",
        "%config InlineBackend.figure_format = 'svg' \n",
        "%matplotlib inline\n",
        "%config IPCompleter.greedy=True  # более лучший автокомплит в блокноте\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = 'https://drive.google.com/drive/folders/1Sc9qSYEE4Mf2z1MVccxwcUCW3MqTdnwa'\n",
        "\n",
        "!pip install gTTS #text to Speach lib for notifications\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "def Notification(text = 'task is done'):\n",
        "  tts = gTTS(text)\n",
        "  print(text)\n",
        "  tts.save('notification.wav')\n",
        "  sound_file = 'notification.wav'\n",
        "  return Audio(sound_file, autoplay=True)\n",
        "\n",
        "# from google.colab import output\n",
        "# def Notification():\n",
        "#   output.eval_js('new Audio(\"https://soundslibmp3.ru/sounds/1599371653_intro-35.mp3\").play()')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/5AGWzmIZ_zeCOCTyVvGR-lwU5ZdiKYbOQyW4qZKQ-kS19bUAV8EKaLI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJUPMjkiG3lh",
        "cellView": "both"
      },
      "source": [
        "#@title system check\n",
        "print('Python       :', sys.version.split('\\n')[0])\n",
        "print('Numpy        :', np.__version__)\n",
        "print('Tensorflow   :', tf.__version__)\n",
        "print('Keras        :', tf.keras.__version__)\n",
        "tf.test.gpu_device_name() ## Проверяем что у нас работает GPU\n",
        "!nvidia-smi -L ##GPU count and name\n",
        "Notification('hardware and libraries setup is done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mwiYkC3JyDX",
        "cellView": "form"
      },
      "source": [
        "#@title Variables Setup\n",
        "EPOCHS               = 15  # эпох на обучение\n",
        "BATCH_SIZE           = 2048 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\n",
        "LR                   = 1e-4\n",
        "VAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n",
        "\n",
        "CLASS_NUM            = 10  # количество классов в нашей задаче\n",
        "IMG_SIZE             = 224 # какого размера подаем изображения в сеть\n",
        "IMG_CHANNELS         = 3   # у RGB 3 канала\n",
        "input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n",
        "\n",
        "PATH = '/content/'\n",
        "PATH_GDRIVE = '/content/drive/My Drive/Colab Notebooks/car classification/data/'\n",
        "train_dataset_name = 'train_ds_v5.zip'\n",
        "\n",
        "# Устаналиваем конкретное значение random seed для воспроизводимости\n",
        "# os.makedirs(PATH,exist_ok=False)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)  \n",
        "PYTHONHASHSEED = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAxRffMIVEp8",
        "cellView": "both",
        "outputId": "7732eaf9-b1f4-437e-8946-129e15ff2e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "# @title Dataset Setup\n",
        "print('unpacking the pics...')\n",
        "\n",
        "# train DataSet Setup\n",
        "print('unpacking train dataset...')\n",
        "with zipfile.ZipFile(PATH_GDRIVE + 'train/' + train_dataset_name,\"r\") as z:\n",
        "  z.extractall(PATH + 'train')\n",
        "\n",
        "## test DataSet Setup\n",
        "print('unpacking test dataset...')\n",
        "with zipfile.ZipFile(PATH_GDRIVE + 'test/test_upload.zip',\"r\") as z:\n",
        "        z.extractall(PATH)\n",
        "\n",
        "## copy files from G-Drive to Colab env.\n",
        "%cp -av '/content/drive/My Drive/Colab Notebooks/car classification/data/train.csv' '/content'\n",
        "%cp -av '/content/drive/My Drive/Colab Notebooks/car classification/data/sample-submission.csv' '/content'\n",
        "\n",
        "print('cleaning folders...')\n",
        "shutil.rmtree(PATH + 'train/__MACOSX')\n",
        "shutil.rmtree(PATH + '__MACOSX')\n",
        "# shutil.rmtree(PATH + 'sample_data')\n",
        "print('data uploaded...')\n",
        "Notification('pictures uploaded')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unpacking the pics...\n",
            "unpacking train dataset...\n",
            "unpacking test dataset...\n",
            "'/content/drive/My Drive/Colab Notebooks/car classification/data/train.csv' -> '/content/train.csv'\n",
            "'/content/drive/My Drive/Colab Notebooks/car classification/data/sample-submission.csv' -> '/content/sample-submission.csv'\n",
            "cleaning folders...\n",
            "data uploaded...\n",
            "pictures uploaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXVw8GCFXTGG",
        "cellView": "form"
      },
      "source": [
        "# @title Delete all internal directories (muted)\n",
        "# import shutil\n",
        "\n",
        "# for dir_name in range (0,9,1):\n",
        "#   dir_name = str(dir_name)\n",
        "#   try:\n",
        "#     shutil.rmtree('/content/' + str(dir_name))\n",
        "#   except: print(dir_name, 'dir does not exist')\n",
        "\n",
        "# try:\n",
        "#   shutil.rmtree('/content/' + str('__MACOSX'))\n",
        "# except: print(dir_name, 'dir does not exist')\n",
        "\n",
        "# try:\n",
        "#   shutil.rmtree(PATH + 'train/')\n",
        "#   shutil.rmtree(PATH + 'test_upload/')\n",
        "# except: print('deleting all files error')\n",
        "\n",
        "# print('allDone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82lojgMBZxap",
        "cellView": "form"
      },
      "source": [
        "#@title Random pics examples (muted)\n",
        "# print('random pics examples')\n",
        "\n",
        "# train_df = pd.read_csv(PATH+\"train.csv\")\n",
        "# sample_submission = pd.read_csv(PATH+\"sample-submission.csv\")\n",
        "# print('dataset examples\\n',\n",
        "#       train_df.head(),\n",
        "#       '\\n\\ncategories destribution\\n',\n",
        "#       train_df.Category.value_counts())\n",
        "\n",
        "# plt.figure(figsize=(12,8))\n",
        "\n",
        "# random_image = train_df.sample(n=9)\n",
        "# random_image_paths = random_image['Id'].values\n",
        "# random_image_cat = random_image['Category'].values\n",
        "\n",
        "# for index, path in enumerate(random_image_paths):\n",
        "#     im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n",
        "#     plt.subplot(3,3, index+1)\n",
        "#     plt.imshow(im)\n",
        "#     plt.title('Class: '+str(random_image_cat[index]))\n",
        "#     plt.axis('off')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLVi-F5IWjKQ",
        "cellView": "form",
        "outputId": "ef1ca139-be57-45dc-e33a-af3cfdb71055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#@title Pics Generator setup\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    validation_split=VAL_SPLIT, # set validation split\n",
        "    ##pics augumentation\n",
        "    # horizontal_flip=False\n",
        "    # rotation_range = 5,\n",
        "    # width_shift_range=0.1,\n",
        "    # height_shift_range=0.1\n",
        "    )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    PATH + 'train/',      # директория где расположены папки с картинками \n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True, seed=RANDOM_SEED,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    PATH + 'train/',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True, seed=RANDOM_SEED,\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "sample_submission = pd.read_csv(PATH+\"sample-submission.csv\")\n",
        "test_sub_generator = test_datagen.flow_from_dataframe( \n",
        "    dataframe=sample_submission,\n",
        "    directory=PATH+'test_upload/',\n",
        "    x_col=\"Id\",\n",
        "    y_col=None,\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    seed=RANDOM_SEED,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13232 images belonging to 10 classes.\n",
            "Found 2329 images belonging to 10 classes.\n",
            "Found 6675 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io8kBhFM-EUa",
        "cellView": "form"
      },
      "source": [
        "#@title plot_result function\n",
        "def plot_result(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()  \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOWqJtnHiMeQ"
      },
      "source": [
        "## basic experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kjb9wwgh83v"
      },
      "source": [
        "### Xception tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_LBnB9qYeKL",
        "cellView": "both"
      },
      "source": [
        "#@title NN_v1.0 Xception (setup)\n",
        "model_name = 'v1_0.hdf5'\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n",
        "# New head setup\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "# and a logistic layer -- let's say we have 10 classes\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer=optimizers.Adam(lr=LR), \n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKK_-IDhY5ES",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v1.0 Xception (training)\n",
        "checkpoint = ModelCheckpoint(model_name ,\n",
        "                             monitor = ['val_accuracy'],\n",
        "                             verbose = 1, \n",
        "                             mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks=[tensorboard_callback]\n",
        "        )\n",
        "\n",
        "model.save(PATH_GDRIVE + \"models/\" + model_name)\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1PZbgI_Z83X",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v1.1 Xception with LR optimization & Batch Optimization (setup)\n",
        "%reload_ext tensorboard\n",
        "model_name = 'v1_1.hdf5'\n",
        "!rm -rf ./logs/\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                                      histogram_freq=1)\n",
        "\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, \n",
        "                                                                                            decay_steps = 100, \n",
        "                                                                                            decay_rate = 0.9)),\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1, # new_lr = lr * factor. \n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    min_delta=0.0001, cooldown=1, min_lr=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Z2hTLX-1hu",
        "cellView": "form"
      },
      "source": [
        "#@title NN_v1.1 Xception with LR optimization & Batch Optimization (training)\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY0xn1gRFzuh"
      },
      "source": [
        "### EfficientNetB4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlVBIHfwF6mU"
      },
      "source": [
        "### ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUwkoWL5GFnv",
        "cellView": "both"
      },
      "source": [
        "#@title NN_v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization (setup)\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "model_name = 'v3_0_ds4.hdf5'\n",
        "base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                          include_top=False,\n",
        "                          weights=\"imagenet\")\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, \n",
        "                                                                                            decay_steps = 100, \n",
        "                                                                                            decay_rate = 0.9)),\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1, # new_lr = lr * factor. \n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    min_delta=0.0001, cooldown=1, min_lr=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt6qEGq1HI6g",
        "cellView": "both"
      },
      "source": [
        "#@title NN_v3.0 'InceptionResNetV2' with LR optimization & Batch Optimization (training)\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "plot_result(history)\n",
        "Notification()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTNw2u_cGsTN"
      },
      "source": [
        "### without ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "qSNZb8GMG4Pw"
      },
      "source": [
        "#@title NN_v3.1 'InceptionResNetV2' with No LR optimization & Batch Optimization (setup)\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "model_name = 'v3_1_ds2.hdf5'\n",
        "base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                          include_top=False,\n",
        "                          weights=\"imagenet\")\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(0.0005, \n",
        "                                                                                            decay_steps = 100, \n",
        "                                                                                            decay_rate = 0.9)),\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "AUShqOqFG50E"
      },
      "source": [
        "#@title NN_v3.1 'InceptionResNetV2' with No LR optimization & Batch Optimization (training)\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "plot_result(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpQTRUTV1UWl"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPx2Nf69ZxMi"
      },
      "source": [
        "**the idea is:**<br>\n",
        "- to find the  optimal hyperparamets by using TensorBoard (TB)<br>\n",
        "- train the net<br>\n",
        "- add more augmented pics to the categories with the highest confusion according to the confusion matrix<br>\n",
        "- re-train the net<br>\n",
        "- apply the fine-tuning<br><br>\n",
        "<b>TO DO:</b><br>\n",
        "<input type=\"checkbox\">prepare the middle-sized augmented dataset (train_ds_v5))<br>\n",
        "<input type=\"checkbox\">setup TB, API HParams<br>\n",
        "<input type=\"checkbox\">pre-train CNN (1 EPOCH) to find the optimal param <br>\n",
        "<input type=\"checkbox\">full train CNN with the optimal param <br>\n",
        "<input type=\"checkbox\">ConfMatrix setup<br>\n",
        "<input type=\"checkbox\">add more augmented pics (train_ds_v6)<br> \n",
        "<input type=\"checkbox\">full train<br>\n",
        "<input type=\"checkbox\">fine tuning<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtz7mg41E_hE",
        "outputId": "db87780e-78c0-40e9-a50c-acd82fb9d632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#@title Tensorboard Launch & Basic Parametrs Setup\n",
        "%load_ext tensorboard\n",
        "# !rm -rf ./logs/ #clean existing logs\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "metrics_callback = tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gidHGYDLNe3D",
        "cellView": "both"
      },
      "source": [
        "#@title NN BaseModel Setup\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "def model_setup(train_setup = False, # Freez the NN body to train only head\n",
        "                model_name = 'InceptionResNetV2'):\n",
        "  model_name = model_name\n",
        "  base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                                 include_top=False,\n",
        "                                 weights=\"imagenet\"\n",
        "                                 )\n",
        "  # Freeze the base_model\n",
        "  base_model.trainable = train_setup\n",
        "\n",
        "  x = base_model.output\n",
        "  x = BatchNormalization()(x, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by6tXoYAx4o7",
        "cellView": "both"
      },
      "source": [
        "#@title Tensorboard HyperParams Tuning\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "##list of params to find optimumal set\n",
        "# HP_NUM_UNITS=hp.HParam('num_units', hp.Discrete([ 256, 512]))\n",
        "HP_DROPOUT=hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "HP_LEARNING_RATE= hp.HParam('learning_rate', hp.Discrete([1e-3, 5e-4, 1e-4]))\n",
        "HP_OPTIMIZER=hp.HParam('optimizer', hp.Discrete(['adam']))\n",
        "\n",
        "METRIC_ACCURACY='accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "      hparams=[HP_OPTIMIZER, HP_DROPOUT, HP_LEARNING_RATE],\n",
        "      metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
        "      )\n",
        "\n",
        "def train_test_model(hparams):\n",
        "  model = model_setup()\n",
        "  model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "  model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = 1)\n",
        "  scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "  print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "  \n",
        "  return accuracy\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "session_num = 0\n",
        "\n",
        "for dropout_rate in HP_DROPOUT.domain.values:\n",
        "  for lr in (HP_LEARNING_RATE.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_LEARNING_RATE: lr,\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1\n",
        "      \n",
        "Notification('parameters research is done')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trzXx-HXDD_W",
        "cellView": "form"
      },
      "source": [
        "#@title Confusion Matrix Log Setup\n",
        "#source: https://www.tensorflow.org/tensorboard/image_summaries\n",
        "\n",
        "def plot_confusion_matrix(cm, # (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "                          class_names # (array, shape = [n]): String names of the integer classes):\n",
        "\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Compute the labels from the normalized confusion matrix.\n",
        "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure\n",
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(test_images)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "  # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# !rm -rf logs/image\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_kePxVftUQe",
        "cellView": "form"
      },
      "source": [
        "#@title CNN model setup\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "def model_setup(train_setup = False, # Freez the NN body to train only head\n",
        "                model_name = 'InceptionResNetV2'):\n",
        "  model_name = model_name\n",
        "  base_model = InceptionResNetV2(input_shape=input_shape,\n",
        "                                 include_top=False,\n",
        "                                 weights=\"imagenet\"\n",
        "                                 )\n",
        "  # Freeze the base_model\n",
        "  base_model.trainable = train_setup\n",
        "\n",
        "  x = base_model.output\n",
        "  x = BatchNormalization()(x, training=False)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(100, activation='relu', kernel_regularizer = 'l2')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  predictions = Dense(CLASS_NUM, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOg1ZNIv6FLm",
        "cellView": "both"
      },
      "source": [
        "#@title CNN optimal param research\n",
        "!rm -rf ./logs/ #clean existing logs\n",
        "\n",
        "model = model_setup(train_setup = False,\n",
        "                    model_name = 'InceptionResNetV2')\n",
        "\n",
        "model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = 1,\n",
        "        callbacks = [cm_callback,\n",
        "                     tensorboard_callback,\n",
        "                     hp_callback\n",
        "                     ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6KLjaIuKLlw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "7_N-yTpWw0uS"
      },
      "source": [
        "#@title CNN with optimal params training\n",
        "optimal_LR = LR\n",
        "model_name = 'InceptionResNetV2_optimal.hdf5'\n",
        "model = model_setup(train_setup = False,\n",
        "                    model_name = model_name)\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(LR = optimal_LR, \n",
        "                                                               decay_steps = 100, \n",
        "                                                               decay_rate = 0.9))\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(learning_rate = learning_rate,\n",
        "                                        metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = [tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
        "                     hp.KerasCallback(logdir, hparams)]  # log hparams\n",
        "                    \n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "Notification('Neural Network Training is done')\n",
        "\n",
        "##live tensorboard\n",
        "# !tensorboard dev upload --logdir logs --name \"Alex_test\" --description \"Alex_description\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuFu1qa8xWKS",
        "cellView": "both"
      },
      "source": [
        "#@title NN_v3.2 'InceptionResNetV2' with LR & Batch Optimization + FineTuning (fine-tuning)\n",
        "model_name = 'v3_2_ds4_finetuned.hdf5'\n",
        "base_model.trainable = True\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=optimizers.Adam(1e-5))\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_name , \n",
        "                             monitor = ['val_accuracy'] , \n",
        "                             verbose = 1  , mode = 'max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_data = test_generator, \n",
        "        validation_steps = len(test_generator),\n",
        "        epochs = EPOCHS,\n",
        "        callbacks = callbacks_list)\n",
        "\n",
        "model.save(PATH_GDRIVE + 'models/' + model_name)\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
        "plot_result(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8cDwP6CoWu"
      },
      "source": [
        "## submission generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lMVvQpj5f2R"
      },
      "source": [
        "model.load_weights(PATH_GDRIVE + 'models/'+\n",
        "                  #  'v1_0.hdf5',\n",
        "                  #  'v1_1.hdf5',\n",
        "                  #  'v2_0.hdf5',\n",
        "                  #  'v3_0.hdf5',\n",
        "                  #  'v3_1.hdf5',\n",
        "                  #  'v3_0_ds3.hdf5',\n",
        "                  #  'v3_0_ds4.hdf5',\n",
        "                   model_name\n",
        "                   )\n",
        "scores = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "test_sub_generator.reset()\n",
        "predictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n",
        "predictions = np.argmax(predictions, axis=-1) #multiple categories\n",
        "label_map = (train_generator.class_indices)\n",
        "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
        "predictions = [label_map[k] for k in predictions]\n",
        "\n",
        "filenames_with_dir=test_sub_generator.filenames\n",
        "submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n",
        "submission['Id'] = submission['Id'].replace('test_upload/','')\n",
        "submission.to_csv(PATH_GDRIVE + 'submission.csv', index=False)\n",
        "print('Submit saved.')\n",
        "Notification()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXRiQ_h3voF"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(),signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}